version: '3.9'
services:
  xinference:
    image: xprobe/xinference:v0.12.1
    restart: always
    command: xinference-local -H 0.0.0.0
    # ports: # 不使用 host network 时可打开.
    #  - "9997:9997"
    network_mode: "host"
    # 将本地路径(~/xinference)挂载到容器路径(/root/.xinference)中,
    # 详情见: https://inference.readthedocs.io/zh-cn/latest/getting_started/using_docker_image.html
    volumes:
      - ~/xinference:/root/.xinference
      # - ~/xinference/cache/huggingface:/root/.cache/huggingface
      # - ~/xinference/cache/modelscope:/root/.cache/modelscope
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
    # 模型源更改为 ModelScope, 默认为 HuggingFace
    # environment:
    #   - XINFERENCE_MODEL_SRC=modelscope
  chatchat:
    image: chatimage/chatchat:0.3.0-2024-0624
    restart: always
    # ports: # 不使用 host network 时可打开.
    #   - "7861:7861"
    #   - "8501:8501"
    network_mode: "host"
    # 将本地路径(~/chatchat/data)挂载到容器默认数据路径(/usr/local/lib/python3.11/site-packages/chatchat/data)中
    # volumes:
    #   - ~/chatchat/data:/usr/local/lib/python3.11/site-packages/chatchat/data
