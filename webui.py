import gradio as gr
import os
import shutil
import knowledge_based_chatglm as kb


def get_file_list():
    if not os.path.exists("content"):
        return []
    return [f for f in os.listdir("content")]


file_list = get_file_list()

embedding_model_dict_list = list(kb.embedding_model_dict.keys())

llm_model_dict_list = list(kb.llm_model_dict.keys())


def upload_file(file):
    if not os.path.exists("content"):
        os.mkdir("content")
    filename = os.path.basename(file.name)
    shutil.move(file.name, "content/" + filename)
    # file_listÈ¶ñ‰ΩçÊèíÂÖ•Êñ∞‰∏ä‰º†ÁöÑÊñá‰ª∂
    file_list.insert(0, filename)
    return gr.Dropdown.update(choices=file_list, value=filename)


def get_answer(query, vector_store, history):
    resp, history = kb.get_knowledge_based_answer(
        query=query, vector_store=vector_store, chat_history=history)
    return history, history


def get_model_status(history):
    return history + [[None, "Ê®°ÂûãÂ∑≤ÂÆåÊàêÂä†ËΩΩÔºåËØ∑ÈÄâÊã©Ë¶ÅÂä†ËΩΩÁöÑÊñáÊ°£"]]


def get_file_status(history):
    return history + [[None, "ÊñáÊ°£Â∑≤ÂÆåÊàêÂä†ËΩΩÔºåËØ∑ÂºÄÂßãÊèêÈóÆ"]]


with gr.Blocks(css="""
.importantButton {
    background: linear-gradient(45deg, #7e0570,#5d1c99, #6e00ff) !important;
    border: none !important;
}

.importantButton:hover {
    background: linear-gradient(45deg, #ff00e0,#8500ff, #6e00ff) !important;
    border: none !important;
}

""") as demo:
    gr.Markdown(
        f"""
# üéâlangchain-ChatGLM WebUIüéâ

üëç [https://github.com/imClumsyPanda/langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)

""")
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot([[None, """Ê¨¢Ëøé‰ΩøÁî® langchain-ChatGLM Web UIÔºåÂºÄÂßãÊèêÈóÆÂâçÔºåËØ∑‰æùÊ¨°Â¶Ç‰∏ã 3 ‰∏™Ê≠•È™§Ôºö
1. ÈÄâÊã©ËØ≠Ë®ÄÊ®°Âûã„ÄÅEmbedding Ê®°ÂûãÂèäÁõ∏ÂÖ≥ÂèÇÊï∞ÂêéÁÇπÂáª"step.1: setting"ÔºåÂπ∂Á≠âÂæÖÂä†ËΩΩÂÆåÊàêÊèêÁ§∫
2. ‰∏ä‰º†ÊàñÈÄâÊã©Â∑≤ÊúâÊñá‰ª∂‰Ωú‰∏∫Êú¨Âú∞Áü•ËØÜÊñáÊ°£ËæìÂÖ•ÂêéÁÇπÂáª"step.2 loading"ÔºåÂπ∂Á≠âÂæÖÂä†ËΩΩÂÆåÊàêÊèêÁ§∫
3. ËæìÂÖ•Ë¶ÅÊèê‰∫§ÁöÑÈóÆÈ¢òÂêéÁÇπÂáª"step.3 asking" """]],
                                 elem_id="chat-box",
                                 show_label=False).style(height=600)
        with gr.Column(scale=1):
            with gr.Column():
                llm_model = gr.Radio(llm_model_dict_list,
                                     label="llm model",
                                     value="chatglm-6b",
                                     interactive=True)
                LLM_HISTORY_LEN = gr.Slider(0,
                                            10,
                                            value=3,
                                            step=1,
                                            label="LLM history len",
                                            interactive=True)
                embedding_model = gr.Radio(embedding_model_dict_list,
                                           label="embedding model",
                                           value="text2vec",
                                           interactive=True)
                VECTOR_SEARCH_TOP_K = gr.Slider(1,
                                                20,
                                                value=6,
                                                step=1,
                                                label="vector search top k",
                                                interactive=True)
                load_model_button = gr.Button("step.1Ôºösetting")
                load_model_button.click(lambda *args:
                                        kb.init_cfg(args[0], args[1], args[2], args[3]),
                                        show_progress=True,
                                        api_name="init_cfg",
                                        inputs=[llm_model, embedding_model, LLM_HISTORY_LEN,VECTOR_SEARCH_TOP_K]
                                        ).then(
                    get_model_status, chatbot, chatbot
                )

            with gr.Column():
                with gr.Tab("select"):
                    selectFile = gr.Dropdown(file_list,
                                             label="content file",
                                             interactive=True,
                                             value=file_list[0] if len(file_list) > 0 else None)
                with gr.Tab("upload"):
                    file = gr.File(label="content file",
                                   file_types=['.txt', '.md', '.docx']
                                   ).style(height=100)
                    # Â∞Ü‰∏ä‰º†ÁöÑÊñá‰ª∂‰øùÂ≠òÂà∞contentÊñá‰ª∂Â§π‰∏ã,Âπ∂Êõ¥Êñ∞‰∏ãÊãâÊ°Ü
                    file.upload(upload_file,
                                inputs=file,
                                outputs=selectFile)
                history = gr.State([])
                vector_store = gr.State()
                load_button = gr.Button("step.2Ôºöloading")
                load_button.click(lambda fileName:
                                  kb.init_knowledge_vector_store(
                                      "content/" + fileName),
                                  show_progress=True,
                                  api_name="init_knowledge_vector_store",
                                  inputs=selectFile,
                                  outputs=vector_store
                                  ).then(
                    get_file_status,
                    chatbot,
                    chatbot,
                    show_progress=True,
                )

    with gr.Row():
        with gr.Column(scale=2):
            query = gr.Textbox(show_label=False,
                               placeholder="Prompts",
                               lines=1,
                               value="Áî®200Â≠óÊÄªÁªì‰∏Ä‰∏ã"
                               ).style(container=False)
        with gr.Column(scale=1):
            generate_button = gr.Button("step.3Ôºöasking",
                                        elem_classes="importantButton")
            generate_button.click(get_answer,
                                  [query, vector_store, chatbot],
                                  [chatbot, history],
                                  api_name="get_knowledge_based_answer"
                                  )

demo.queue(concurrency_count=3).launch(
    server_name='0.0.0.0', share=False, inbrowser=False)
