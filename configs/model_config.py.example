import os
import logging
import torch
# 日志格式
LOG_FORMAT = "%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s"
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logging.basicConfig(format=LOG_FORMAT)



embedding_model_dict = {
    ## 填写在线大模型API相关信息或者本地模型名称
    "Azure-OpenAI": {
        "model_name": "text-embedding-ada-002",
        "deployment_name": "",
        "api_base_url": "https://{Yours}.openai.azure.com",
        "api_key": "",
        "api_version": "2023-05-15",
    }
    "OpenAI": {
        "model_name":"text-embedding-ada-002",
        "api_base_url": "https://api.openai.com/v1",
        "api_key": "your api keys"
    },

    "Local-Embedding": {
        "model_name": "bge-large-zh", #本地模型名称
        "local_model_path": "your local model path", # 本地模型的绝对路径
    }
}
llm_model_dict = {
    # 调用chatgpt时如果报出： urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.openai.com', port=443):
    #  Max retries exceeded with url: /v1/chat/completions
    # 则需要将urllib3版本修改为1.25.11
    # 如果依然报urllib3.exceptions.MaxRetryError: HTTPSConnectionPool，则将https改为http
    # 参考https://zhuanlan.zhihu.com/p/350015032

    # 如果报出：raise NewConnectionError(
    # urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001FE4BDB85E0>:
    # Failed to establish a new connection: [WinError 10060]
    # 则是因为内地和香港的IP都被OPENAI封了，需要切换为日本、新加坡等地

    # 如果出现WARNING: Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in
    # 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.
    # 需要添加代理访问(正常开的代理软件可能会拦截不上)需要设置配置openai_proxy 或者 使用环境遍历OPENAI_PROXY 进行设置

    # 在这里的model_name填写Openai API中你的模型，支持微调后和原始的模型。
    "OpenAI": {
        "model_name": "",
        "api_base_url": "https://api.openai.com/v1",
        "api_key": os.environ.get("OPENAI_API_KEY")
    },

    # 在这里的model_name填写Azure Openai API中你的模型，支持微调后和原始的模型。Azure OpenAI在国内可以正常访问
    "Azure-OpenAI": {
        "deployment_name": "",
        "api_base_url": "https://{Yours}.openai.azure.com",
        "api_key": "",
        "api_version": "2023-05-15",
        "model_name": "",
        "model_version": "0613"
    }

    # Claude 模型对话，需填写模型名称和Key
    "Anthropic"：{
        "model_name": "",
        "api_base_url": "https://api.anthropic.com"
        "api_key": "",
    }

    # 本地模型，需填写模型名称和本地模型路径
    "Local-LLM": {
        "model_name": "chatglm2-6b-32k",
        "local_model_path": "THUDM/chatglm2-6b-32k",  # 本地模型地址
        "api_base_url": "http://localhost:8888/v1",  # "URL需要与运行fastchat服务端的server_config.FSCHAT_OPENAI_API一致
        "api_key": "EMPTY"
    },


}

## 以下内容作为激活的类型

# 选用的 Embedding 名称(类型)
EMBEDDING_MODEL = "Local-Embedding"
# 选用的 LLM 名称(类型)
LLM_MODEL = "Local-LLM"
llm_model_args = {
    "streaming": True,
    "verbose": True,
    "temperature": 0.9,
    "max_tokens": 1000,
}

# Embedding 模型运行设备
EMBEDDING_DEVICE = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
# LLM 运行设备
LLM_DEVICE = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"


# 日志存储路径
LOG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "logs")
if not os.path.exists(LOG_PATH):
    os.mkdir(LOG_PATH)

# 知识库默认存储路径
KB_ROOT_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge_base")

# 数据库默认存储路径。
# 如果使用sqlite，可以直接修改DB_ROOT_PATH；如果使用其它数据库，请直接修改SQLALCHEMY_DATABASE_URI。
DB_ROOT_PATH = os.path.join(KB_ROOT_PATH, "info.db")
SQLALCHEMY_DATABASE_URI = f"sqlite:///{DB_ROOT_PATH}"

# 可选向量库类型及对应配置
kbs_config = {
    "faiss": {
    },
    "milvus": {
        "host": "127.0.0.1",
        "port": "19530",
        "user": "",
        "password": "",
        "secure": False,
    },
    "pg": {
        "connection_uri": "postgresql://postgres:postgres@127.0.0.1:5432/langchain_chatchat",
    }
}

# 默认分词方法，默认为ChatGLM中使用的
# SpacyTextSplitter
# MarkdownHeaderTextSplitter
# CharacterTextSplitter.from_tiktoken_encoder
# CharacterTextSplitter.from_huggingface_tokenizer
# NLTKTextSplitter
# SentenceTransformersTokenTextSplitter
# 等Langchain支持的Text_splitter

TEXT_SPLITTER_NAME = "MarkdownHeaderTextSplitter"

# 默认向量库类型。可选：faiss, milvus, pg.
DEFAULT_VS_TYPE = "faiss"

# 缓存向量库数量
CACHED_VS_NUM = 1

# 知识库中单段文本长度
CHUNK_SIZE = 250

# 知识库中相邻文本重合长度
OVERLAP_SIZE = 50

# 知识库匹配向量数量
VECTOR_SEARCH_TOP_K = 5

# 知识库匹配相关度阈值，取值范围在0-1之间，SCORE越小，相关度越高，取到1相当于不筛选，建议设置在0.5左右
SCORE_THRESHOLD = 1

# 搜索引擎匹配结题数量
SEARCH_ENGINE_TOP_K = 5

# nltk 模型存储路径
NLTK_DATA_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "nltk_data")

# 基于本地知识问答的提示词模版（使用Jinja2语法，简单点就是用双大括号代替f-string的单大括号
PROMPT_TEMPLATE = """<指令>根据已知信息，简洁和专业的来回答问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题”，不允许在答案中添加编造成分，答案请使用中文。 </指令>

<已知信息>{{ context }}</已知信息>

<问题>{{ question }}</问题>"""

# API 是否开启跨域，默认为False，如果需要开启，请设置为True
# is open cross domain
OPEN_CROSS_DOMAIN = False

# Bing 搜索必备变量
# 使用 Bing 搜索需要使用 Bing Subscription Key,需要在azure port中申请试用bing search
# 具体申请方式请见
# https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/create-bing-search-service-resource
# 使用python创建bing api 搜索实例详见:
# https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/quickstarts/rest/python
BING_SEARCH_URL = "https://api.bing.microsoft.com/v7.0/search"
# 注意不是bing Webmaster Tools的api key，

# 此外，如果是在服务器上，报Failed to establish a new connection: [Errno 110] Connection timed out
# 是因为服务器加了防火墙，需要联系管理员加白名单，如果公司的服务器的话，就别想了GG
BING_SUBSCRIPTION_KEY = ""

# 是否开启中文标题加强，以及标题增强的相关配置
# 通过增加标题判断，判断哪些文本为标题，并在metadata中进行标记；
# 然后将文本与往上一级的标题进行拼合，实现文本信息的增强。
ZH_TITLE_ENHANCE = False