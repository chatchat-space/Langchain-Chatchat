version: '3.9'
services:
  xinference:
    image: xprobe/xinference:v0.12.1
    restart: always
    command: xinference-local -H 0.0.0.0
    # ports: # 不使用 host network 时可打开.
    #  - "9997:9997"
    network_mode: "host"
    volumes:
      # 将本地路径(~/xinference)挂载到容器路径(/root/.xinference)中,
      # 详情见: https://inference.readthedocs.io/zh-cn/latest/getting_started/using_docker_image.html
      - ~/xinference:/root/.xinference
      # - ~/xinference/cache/huggingface:/root/.cache/huggingface
      # - ~/xinference/cache/modelscope:/root/.cache/modelscope
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
  chatchat:
    image: chatimage/chatchat:0.3.0-0623
    restart: always
    # ports: # 不使用 host network 时可打开.
    #   - "7861:7861"
    #   - "8501:8501"
    network_mode: "host"
    # 将本地路径(~/chatchat/data)挂载到容器默认数据路径(/usr/local/lib/python3.11/site-packages/chatchat/data)中
    # 将本地模型接入配置文件(~/chatchat/model_providers.yaml)挂载到容器默认模型接入配置文件路径(/usr/local/lib/python3.11/site-packages/chatchat/configs/)中
    # volumes:
    #   - ~/chatchat/data:/usr/local/lib/python3.11/site-packages/chatchat/data
    #   - ~/chatchat/model_providers.yaml:/usr/local/lib/python3.11/site-packages/chatchat/configs/model_providers.yaml