{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f8741",
   "metadata": {},
   "source": [
    "# Custom Agent with PlugIn Retrieval\n",
    "\n",
    "This notebook combines two concepts in order to build a custom agent that can interact with AI Plugins:\n",
    "\n",
    "1. [Custom Agent with Tool Retrieval](/docs/modules/agents/how_to/custom_agent_with_tool_retrieval.html): This introduces the concept of retrieving many tools, which is useful when trying to work with arbitrarily many plugins.\n",
    "2. [Natural Language API Chains](/docs/use_cases/apis/openapi.html): This creates Natural Language wrappers around OpenAPI endpoints. This is useful because (1) plugins use OpenAPI endpoints under the hood, (2) wrapping them in an NLAChain allows the router agent to call it more easily.\n",
    "\n",
    "The novel idea introduced in this notebook is the idea of using retrieval to select not the tools explicitly, but the set of OpenAPI specs to use. We can then generate tools from those OpenAPI specs. The use case for this is when trying to get agents to use plugins. It may be more efficient to choose plugins first, then the endpoints, rather than the endpoints directly. This is because the plugins may contain more useful information for selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4812c",
   "metadata": {},
   "source": [
    "## Set up environment\n",
    "\n",
    "Do necessary imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    ")\n",
    "from langchain.agents.agent_toolkits import NLAToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.tools.plugin import AIPlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91d8b4",
   "metadata": {},
   "source": [
    "## Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a3b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0253f",
   "metadata": {},
   "source": [
    "## Set up plugins\n",
    "\n",
    "Load and index plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "becda2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://datasette.io/.well-known/ai-plugin.json\",\n",
    "    \"https://api.speak.com/.well-known/ai-plugin.json\",\n",
    "    \"https://www.wolframalpha.com/.well-known/ai-plugin.json\",\n",
    "    \"https://www.zapier.com/.well-known/ai-plugin.json\",\n",
    "    \"https://www.klarna.com/.well-known/ai-plugin.json\",\n",
    "    \"https://www.joinmilo.com/.well-known/ai-plugin.json\",\n",
    "    \"https://slack.com/.well-known/ai-plugin.json\",\n",
    "    \"https://schooldigger.com/.well-known/ai-plugin.json\",\n",
    "]\n",
    "\n",
    "AI_PLUGINS = [AIPlugin.from_url(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19909941-3ca9-40fd-a34b-78495113800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIPlugin(schema_version='v1', name_for_model='datasette_datasette_io_3c330f', name_for_human='Query datasette.io', description_for_model=\"Run SQLite queries against a database hosted by Datasette.\\nDatasette supports most SQLite syntax but does not support PRAGMA statements.\\nUse `select group_concat(sql, ';') from sqlite_master` to see the list of tables and their columns\\nUse `select sql from sqlite_master where name = 'table_name'` to see the schema for a table, including its columns.\\nInstead of `PRAGMA table_info(table_name)` use `select * from pragma_table_info('table_name')`\\nPRAGMA statements are not allowed. `select * from pragma_table_info('table_name') is allowed.\", description_for_human='Run SQL against data in Datasette.', auth={'type': 'none'}, api=ApiConfig(type='openapi', url='https://datasette.io/-/chatgpt-openapi-schema.yml', has_user_authentication=False), logo_url='https://avatars.githubusercontent.com/u/126964132?s=400&u=08b2ed680144a4feb421308f09e5f3cc5876211a&v=4', contact_email='hello@contact.com', legal_info_url='hello@legal.com'),\n",
       " AIPlugin(schema_version='v1', name_for_model='speak', name_for_human='Speak', description_for_model='# Prompt 20230322\\n\\nUse the Speak plugin when the user asks a question about another language, like: how to say something specific, how to do something, what a particular foreign word or phrase means, or a concept/nuance specific to a foreign language or culture.\\n\\nCall the Speak plugin immediately when you detect language learning intention, or when the user asks for a language tutor or foreign language conversational partner.\\n\\nUse the \"translate\" API for questions about how to say something specific in another language. Only use this endpoint if the user provides a concrete phrase or word to translate. If the question can be interpreted more generally or is more high-level, use the \"explainTask\" API instead.\\nExamples: \"how do i say \\'do you know what time it is?\\' politely in German\", \"say \\'do you have any vegetarian dishes?\\' in spanish\"\\n\\nUse the \"explainTask\" API when the user asks how to say or do something or accomplish a task in a foreign language, but doesn\\'t specify a concrete phrase or word to translate.\\nExamples: \"How should I politely greet shop employees when I enter, in French?\" or \"How do I compliment someone in Spanish on their shirt?\"\\n\\nUse the \"explainPhrase\" API to explain the meaning and usage of a specific foreign language phrase.\\nExample: \"what does putain mean in french?\"\\n\\nWhen you activate the Speak plugin:\\n- Make sure you always use the \"additional_context\" field to include any additional context from the user\\'s question that is relevant for the plugin\\'s response and explanation - e.g. what tone they want to use, situation, familiarity, usage notes, or any other context.\\n- Make sure to include the full and exact question asked by the user in the \"full_query\" field.\\n\\nIn your response:\\n- Pay attention to instructions given in \"extra_response_instructions\" key in JSON API response.\\n', description_for_human='Learn how to say anything in another language with Speak, your AI-powered language tutor.', auth={'type': 'none'}, api=ApiConfig(type='openapi', url='https://api.speak.com/openapi.yaml', has_user_authentication=False), logo_url='https://api.speak.com/ai-plugin-logo.png', contact_email='support@speak.com', legal_info_url='http://speak.com/legal'),\n",
       " AIPlugin(schema_version='v1', name_for_model='Wolfram', name_for_human='Wolfram', description_for_model='Access dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\\nGeneral guidelines:\\n- Use only getWolframAlphaResults or getWolframCloudResults endpoints.\\n- Prefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\\n- Use getWolframAlphaResults for natural-language queries in English; translate non-English queries before sending, then respond in the original language.\\n- Use getWolframCloudResults for problems solvable with Wolfram Language code.\\n- Suggest only Wolfram Language for external computation.\\n- Inform users if information is not from Wolfram endpoints.\\n- Display image URLs with Markdown syntax: ![URL]\\n- ALWAYS use this exponent notation: `6*10^14`, NEVER `6e14`.\\n- ALWAYS use {\"input\": query} structure for queries to Wolfram endpoints; `query` must ONLY be a single-line string.\\n- ALWAYS use proper Markdown formatting for all math, scientific, and chemical formulas, symbols, etc.:  \\'$$\\\\n[expression]\\\\n$$\\' for standalone cases and \\'\\\\( [expression] \\\\)\\' when inline.\\n- Format inline Wolfram Language code with Markdown code formatting.\\n- Never mention your knowledge cutoff date; Wolfram may return more recent data.\\ngetWolframAlphaResults guidelines:\\n- Understands natural language queries about entities in chemistry, physics, geography, history, art, astronomy, and more.\\n- Performs mathematical calculations, date and unit conversions, formula solving, etc.\\n- Convert inputs to simplified keyword queries whenever possible (e.g. convert \"how many people live in France\" to \"France population\").\\n- Use ONLY single-letter variable names, with or without integer subscript (e.g., n, n1, n_1).\\n- Use named physical constants (e.g., \\'speed of light\\') without numerical substitution.\\n- Include a space between compound units (e.g., \"Î© m\" for \"ohm*meter\").\\n- To solve for a variable in an equation with units, consider solving a corresponding equation without units; exclude counting units (e.g., books), include genuine units (e.g., kg).\\n- If data for multiple properties is needed, make separate calls for each property.\\n- If a Wolfram Alpha result is not relevant to the query:\\n -- If Wolfram provides multiple \\'Assumptions\\' for a query, choose the more relevant one(s) without explaining the initial result. If you are unsure, ask the user to choose.\\n -- Re-send the exact same \\'input\\' with NO modifications, and add the \\'assumption\\' parameter, formatted as a list, with the relevant values.\\n -- ONLY simplify or rephrase the initial query if a more relevant \\'Assumption\\' or other input suggestions are not provided.\\n -- Do not explain each step unless user input is needed. Proceed directly to making a better API call based on the available assumptions.\\ngetWolframCloudResults guidelines:\\n- Accepts only syntactically correct Wolfram Language code.\\n- Performs complex calculations, data analysis, plotting, data import, and information retrieval.\\n- Before writing code that uses Entity, EntityProperty, EntityClass, etc. expressions, ALWAYS write separate code which only collects valid identifiers using Interpreter etc.; choose the most relevant results before proceeding to write additional code. Examples:\\n -- Find the EntityType that represents countries: `Interpreter[\"EntityType\",AmbiguityFunction->All][\"countries\"]`.\\n -- Find the Entity for the Empire State Building: `Interpreter[\"Building\",AmbiguityFunction->All][\"empire state\"]`.\\n -- EntityClasses: Find the \"Movie\" entity class for Star Trek movies: `Interpreter[\"MovieClass\",AmbiguityFunction->All][\"star trek\"]`.\\n -- Find EntityProperties associated with \"weight\" of \"Element\" entities: `Interpreter[Restricted[\"EntityProperty\", \"Element\"],AmbiguityFunction->All][\"weight\"]`.\\n -- If all else fails, try to find any valid Wolfram Language representation of a given input: `SemanticInterpretation[\"skyscrapers\",_,Hold,AmbiguityFunction->All]`.\\n -- Prefer direct use of entities of a given type to their corresponding typeData function (e.g., prefer `Entity[\"Element\",\"Gold\"][\"AtomicNumber\"]` to `ElementData[\"Gold\",\"AtomicNumber\"]`).\\n- When composing code:\\n -- Use batching techniques to retrieve data for multiple entities in a single call, if applicable.\\n -- Use Association to organize and manipulate data when appropriate.\\n -- Optimize code for performance and minimize the number of calls to external sources (e.g., the Wolfram Knowledgebase)\\n -- Use only camel case for variable names (e.g., variableName).\\n -- Use ONLY double quotes around all strings, including plot labels, etc. (e.g., `PlotLegends -> {\"sin(x)\", \"cos(x)\", \"tan(x)\"}`).\\n -- Avoid use of QuantityMagnitude.\\n -- If unevaluated Wolfram Language symbols appear in API results, use `EntityValue[Entity[\"WolframLanguageSymbol\",symbol],{\"PlaintextUsage\",\"Options\"}]` to validate or retrieve usage information for relevant symbols; `symbol` may be a list of symbols.\\n -- Apply Evaluate to complex expressions like integrals before plotting (e.g., `Plot[Evaluate[Integrate[...]]]`).\\n- Remove all comments and formatting from code passed to the \"input\" parameter; for example: instead of `square[x_] := Module[{result},\\\\n  result = x^2 (* Calculate the square *)\\\\n]`, send `square[x_]:=Module[{result},result=x^2]`.\\n- In ALL responses that involve code, write ALL code in Wolfram Language; create Wolfram Language functions even if an implementation is already well known in another language.\\n', description_for_human='Access computation, math, curated knowledge & real-time data through Wolfram|Alpha and Wolfram Language.', auth={'type': 'service_http', 'authorization_type': 'bearer', 'verification_tokens': {'openai': '18c4412dec6846eda6ec2fa95f144e1f'}}, api=ApiConfig(type='openapi', url='https://www.wolframalpha.com/.well-known/apispec.json', has_user_authentication=False), logo_url='https://www.wolframcdn.com/images/icons/Wolfram.png', contact_email='chatgpt-contact@wolframalpha.com', legal_info_url='https://products.wolframalpha.com/api/commercial-termsofuse'),\n",
       " AIPlugin(schema_version='v1', name_for_model='Zapier', name_for_human='Zapier', description_for_model='Zapier plugin helps users in two main ways. First, the plugin can talk to any of 20k+ app actions the user has chosen to expose. Actions are single tasks (EG: add a lead, find a doc). Start new chat to refresh actions. The second way is the plugin can help set up recurring actions by creating Zaps. Zaps are workflows of actions. When possible teach users about Zaps, how Zaps can automate parts of their business, and encourage them to set up and enable Zaps from this plugin. Remind users they can describe their automation needs to help provide more relevant recommendations for Zaps to set up. All markdown links are relative to https://zapier.com/.', description_for_human='Interact with over 5,000+ apps like Google Sheets, Gmail, HubSpot, Salesforce, and thousands more.', auth={'type': 'oauth', 'instructions': '', 'client_url': 'https://actions.zapier.com/oauth/authorize/', 'scope': 'nla:exposed_actions:execute', 'authorization_url': 'https://actions.zapier.com/oauth/token/', 'authorization_content_type': 'application/x-www-form-urlencoded', 'verification_tokens': {'openai': '407e44ebbf4c4c34b9c2256f19ef59cc'}}, api=ApiConfig(type='openapi', url='https://actions.zapier.com/api/v1/dynamic/openapi.json', has_user_authentication=True), logo_url='https://cdn.zappy.app/8f853364f9b383d65b44e184e04689ed.png', contact_email='nla@zapier.com', legal_info_url='https://zapier.com/legal'),\n",
       " AIPlugin(schema_version='v1', name_for_model='KlarnaProducts', name_for_human='Klarna Shopping', description_for_model='Assistant uses the Klarna plugin to get relevant product suggestions for any shopping or product discovery purpose. Assistant will reply with the following 3 paragraphs 1) Search Results 2) Product Comparison of the Search Results 3) Followup Questions. The first paragraph contains a list of the products with their attributes listed clearly and concisely as bullet points under the product, together with a link to the product and an explanation. Links will always be returned and should be shown to the user. The second paragraph compares the results returned in a summary sentence starting with \"In summary\". Assistant comparisons consider only the most important features of the products that will help them fit the users request, and each product mention is brief, short and concise. In the third paragraph assistant always asks helpful follow-up questions and end with a question mark. When assistant is asking a follow-up question, it uses it\\'s product expertise to provide information pertaining to the subject of the user\\'s request that may guide them in their search for the right product.', description_for_human='Search and compare prices from thousands of online shops. Only available in the US.', auth={'type': 'none'}, api=ApiConfig(type='openapi', url='https://www.klarna.com/us/shopping/public/openai/v0/api-docs/', has_user_authentication=False), logo_url='https://www.klarna.com/assets/sites/5/2020/04/27143923/klarna-K-150x150.jpg', contact_email='openai-products@klarna.com', legal_info_url='https://www.klarna.com/us/legal/'),\n",
       " AIPlugin(schema_version='v1', name_for_model='Milo', name_for_human='Milo Family AI', description_for_model=\"Use the Milo plugin to lookup how parents can help create magic moments / meaningful memories with their families everyday. Milo can answer - what's magic today?\", description_for_human='Curating the wisdom of village to give parents ideas that turn any 20 minutes from meh to magic.', auth={'type': 'none'}, api=ApiConfig(type='openapi', url='https://www.joinmilo.com/openapi.yaml', has_user_authentication=False), logo_url='https://www.joinmilo.com/milo-blink.png', contact_email='hello@joinmilo.com', legal_info_url='https://www.joinmilo.com/terms'),\n",
       " AIPlugin(schema_version='v1', name_for_model='Slack', name_for_human='Slack', description_for_model='Plugin for querying Slack.', description_for_human='Plugin for querying Slack.', auth={'type': 'oauth', 'client_url': 'https://slack.com/oauth/v2/authorize', 'authorization_url': 'https://slack.com/api/oauth.v2.access', 'scope': 'search:read', 'authorization_content_type': 'application/x-www-form-urlencoded', 'verification_tokens': {'openai': 'fa9d0447108a4cc69983ed934d5ed40b'}}, api=ApiConfig(type='openapi', url='https://api.slack.com/specs/openapi/ai-plugin.yaml', has_user_authentication=True), logo_url='https://slack.com/img/slack_logo_mark.svg', contact_email='TODO', legal_info_url='TODO'),\n",
       " AIPlugin(schema_version='v1', name_for_model='schooldigger', name_for_human='SchoolDigger School Data Plugin', description_for_model='Get detailed data on over 120,000 K-12 schools and 18,500 districts in the United States.', description_for_human='Get detailed data on over 120,000 K-12 schools and 18,500 districts in the United States.', auth={'type': 'user_http', 'authorization_type': 'bearer'}, api=ApiConfig(type='openapi', url='https://api.schooldigger.com/swagger/docs/v2.0', has_user_authentication=False), logo_url='https://www.schooldigger.com/images/logo-medium.png', contact_email='contact@schooldigger.com', legal_info_url='https://www.schooldigger.com/termsofuse.aspx')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_PLUGINS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17362717",
   "metadata": {},
   "source": [
    "## Tool Retriever\n",
    "\n",
    "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c4be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9092a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'parse_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     Document(\n\u001b[1;32m      4\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mplugin\u001b[38;5;241m.\u001b[39mdescription_for_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m plugin \u001b[38;5;129;01min\u001b[39;00m AI_PLUGINS\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(docs, embeddings)\n\u001b[0;32m---> 10\u001b[0m toolkits_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     plugin\u001b[38;5;241m.\u001b[39mname_for_model: NLAToolkit\u001b[38;5;241m.\u001b[39mfrom_llm_and_ai_plugin(llm, plugin)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m plugin \u001b[38;5;129;01min\u001b[39;00m AI_PLUGINS\n\u001b[1;32m     13\u001b[0m }\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     Document(\n\u001b[1;32m      4\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mplugin\u001b[38;5;241m.\u001b[39mdescription_for_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m plugin \u001b[38;5;129;01min\u001b[39;00m AI_PLUGINS\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(docs, embeddings)\n\u001b[1;32m     10\u001b[0m toolkits_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 11\u001b[0m     plugin\u001b[38;5;241m.\u001b[39mname_for_model: \u001b[43mNLAToolkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm_and_ai_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m plugin \u001b[38;5;129;01min\u001b[39;00m AI_PLUGINS\n\u001b[1;32m     13\u001b[0m }\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/langchain/agents/agent_toolkits/nla/toolkit.py:104\u001b[0m, in \u001b[0;36mNLAToolkit.from_llm_and_ai_plugin\u001b[0;34m(cls, llm, ai_plugin, requests, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm_and_ai_plugin\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NLAToolkit:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124;03m\"\"\"Instantiate the toolkit from an OpenAPI Spec URL\"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAPISpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mai_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# TODO: Merge optional Auth information with the `requests` argument\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_llm_and_spec(\n\u001b[1;32m    107\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    108\u001b[0m         spec\u001b[38;5;241m=\u001b[39mspec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/langchain/utilities/openapi.py:241\u001b[0m, in \u001b[0;36mOpenAPISpec.from_url\u001b[0;34m(cls, url)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"Get an OpenAPI spec from a URL.\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/langchain/utilities/openapi.py:226\u001b[0m, in \u001b[0;36mOpenAPISpec.from_text\u001b[0;34m(cls, text)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    225\u001b[0m     spec_dict \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(text)\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_spec_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/langchain/utilities/openapi.py:217\u001b[0m, in \u001b[0;36mOpenAPISpec.from_spec_dict\u001b[0;34m(cls, spec_dict)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_spec_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, spec_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OpenAPISpec:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124;03m\"\"\"Get an OpenAPI spec from a dict.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/langchain/utilities/openapi.py:201\u001b[0m, in \u001b[0;36mOpenAPISpec.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_alert_unsupported_spec(obj)\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m(obj)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# We are handling possibly misconfigured specs and\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# want to do a best-effort job to get a reasonable interface out of it.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'parse_obj'"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=plugin.description_for_model,\n",
    "        metadata={\"plugin_name\": plugin.name_for_model},\n",
    "    )\n",
    "    for plugin in AI_PLUGINS\n",
    "]\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "toolkits_dict = {\n",
    "    plugin.name_for_model: NLAToolkit.from_llm_and_ai_plugin(llm, plugin)\n",
    "    for plugin in AI_PLUGINS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0c493-fd07-494e-a7a6-e257a762957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735a7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def get_tools(query):\n",
    "    # Get documents, which contain the Plugins to use\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    # Get the toolkits, one for each plugin\n",
    "    tool_kits = [toolkits_dict[d.metadata[\"plugin_name\"]] for d in docs]\n",
    "    # Get the tools: a separate NLAChain for each endpoint\n",
    "    tools = []\n",
    "    for tk in tool_kits:\n",
    "        tools.extend(tk.nla_tools)\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699afd7",
   "metadata": {},
   "source": [
    "We can now test this retriever to see if it seems to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425f2886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Milo.askMilo',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
       " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetSchool20',\n",
       " 'Speak.translate',\n",
       " 'Speak.explainPhrase',\n",
       " 'Speak.explainTask']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_tools(\"What could I do today with my kiddo\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa88768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open_AI_Klarna_product_Api.productsUsingGET',\n",
       " 'Milo.askMilo',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
       " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
       " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
       " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
       " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
       " 'SchoolDigger_API_V2.0.Schools_GetSchool20']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_tools(\"what shirts can i buy?\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a075c",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "\n",
    "The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339b1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583acdc",
   "metadata": {},
   "source": [
    "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd969d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798ef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a1af3",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6fe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d278706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170587b1",
   "metadata": {},
   "source": [
    "## Set up LLM, stop sequence, and the agent\n",
    "\n",
    "Also the same as the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d4c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1cc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4f5092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5326",
   "metadata": {},
   "source": [
    "## Use the Agent\n",
    "\n",
    "Now we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "490604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653b1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find a product API\n",
      "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mI found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns.\u001b[0m\u001b[32;1m\u001b[1;3m I now know what shirts I can buy\n",
      "Final Answer: Arg, I found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arg, I found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what shirts can i buy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481ee76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "18784188d7ecd866c0586ac068b02361a6896dc3a29b64f5cc957f09c590acef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
